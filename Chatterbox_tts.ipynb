{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28",
      "authorship_tag": "ABX9TyMbZDAoLhi30d0UhmdIH1QE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/devendergarg/pingurls/blob/main/Chatterbox_tts.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Uninstall existing libraries to prevent conflicts\n",
        "!pip uninstall -y numpy pandas transformers torch torchaudio\n",
        "\n",
        "# Install the necessary libraries from scratch\n",
        "# This ensures that compatible versions are downloaded and installed together.\n",
        "!pip install chatterbox-tts gradio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "hhdHnmQhA_Eg",
        "outputId": "7a718031-b55f-4bea-8461-00df49301cc1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: numpy 2.0.2\n",
            "Uninstalling numpy-2.0.2:\n",
            "  Successfully uninstalled numpy-2.0.2\n",
            "Found existing installation: pandas 2.2.2\n",
            "Uninstalling pandas-2.2.2:\n",
            "  Successfully uninstalled pandas-2.2.2\n",
            "Found existing installation: transformers 4.52.4\n",
            "Uninstalling transformers-4.52.4:\n",
            "  Successfully uninstalled transformers-4.52.4\n",
            "Found existing installation: torch 2.6.0+cu124\n",
            "Uninstalling torch-2.6.0+cu124:\n",
            "  Successfully uninstalled torch-2.6.0+cu124\n",
            "Found existing installation: torchaudio 2.6.0+cu124\n",
            "Uninstalling torchaudio-2.6.0+cu124:\n",
            "  Successfully uninstalled torchaudio-2.6.0+cu124\n",
            "Collecting chatterbox-tts\n",
            "  Downloading chatterbox_tts-0.1.1-py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.11/dist-packages (5.31.0)\n",
            "Collecting numpy==1.26.0 (from chatterbox-tts)\n",
            "  Downloading numpy-1.26.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.5/58.5 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting resampy==0.4.3 (from chatterbox-tts)\n",
            "  Downloading resampy-0.4.3-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting librosa==0.10.0 (from chatterbox-tts)\n",
            "  Downloading librosa-0.10.0-py3-none-any.whl.metadata (8.3 kB)\n",
            "Collecting s3tokenizer (from chatterbox-tts)\n",
            "  Downloading s3tokenizer-0.1.7.tar.gz (218 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m218.1/218.1 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting torch==2.6.0 (from chatterbox-tts)\n",
            "  Downloading torch-2.6.0-cp311-cp311-manylinux1_x86_64.whl.metadata (28 kB)\n",
            "Collecting torchaudio==2.6.0 (from chatterbox-tts)\n",
            "  Downloading torchaudio-2.6.0-cp311-cp311-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting transformers==4.46.3 (from chatterbox-tts)\n",
            "  Downloading transformers-4.46.3-py3-none-any.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.1/44.1 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting diffusers==0.29.0 (from chatterbox-tts)\n",
            "  Downloading diffusers-0.29.0-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting resemble-perth==1.0.1 (from chatterbox-tts)\n",
            "  Downloading resemble_perth-1.0.1-py3-none-any.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: omegaconf==2.3.0 in /usr/local/lib/python3.11/dist-packages (from chatterbox-tts) (2.3.0)\n",
            "Collecting conformer==0.3.2 (from chatterbox-tts)\n",
            "  Downloading conformer-0.3.2-py3-none-any.whl.metadata (631 bytes)\n",
            "Requirement already satisfied: einops>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from conformer==0.3.2->chatterbox-tts) (0.8.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.11/dist-packages (from diffusers==0.29.0->chatterbox-tts) (8.7.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from diffusers==0.29.0->chatterbox-tts) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.2 in /usr/local/lib/python3.11/dist-packages (from diffusers==0.29.0->chatterbox-tts) (0.32.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from diffusers==0.29.0->chatterbox-tts) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from diffusers==0.29.0->chatterbox-tts) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from diffusers==0.29.0->chatterbox-tts) (0.5.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from diffusers==0.29.0->chatterbox-tts) (11.2.1)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa==0.10.0->chatterbox-tts) (3.0.1)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from librosa==0.10.0->chatterbox-tts) (1.15.3)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from librosa==0.10.0->chatterbox-tts) (1.6.1)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.11/dist-packages (from librosa==0.10.0->chatterbox-tts) (1.5.1)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa==0.10.0->chatterbox-tts) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa==0.10.0->chatterbox-tts) (0.60.0)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from librosa==0.10.0->chatterbox-tts) (0.13.1)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa==0.10.0->chatterbox-tts) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa==0.10.0->chatterbox-tts) (0.5.0.post1)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from librosa==0.10.0->chatterbox-tts) (4.14.0)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa==0.10.0->chatterbox-tts) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa==0.10.0->chatterbox-tts) (1.1.0)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.11/dist-packages (from omegaconf==2.3.0->chatterbox-tts) (4.9.3)\n",
            "Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.11/dist-packages (from omegaconf==2.3.0->chatterbox-tts) (6.0.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->chatterbox-tts) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->chatterbox-tts) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->chatterbox-tts) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch==2.6.0->chatterbox-tts)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch==2.6.0->chatterbox-tts)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch==2.6.0->chatterbox-tts)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.6.0->chatterbox-tts)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch==2.6.0->chatterbox-tts)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch==2.6.0->chatterbox-tts)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch==2.6.0->chatterbox-tts)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch==2.6.0->chatterbox-tts)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch==2.6.0->chatterbox-tts)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->chatterbox-tts) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->chatterbox-tts) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->chatterbox-tts) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch==2.6.0->chatterbox-tts)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->chatterbox-tts) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->chatterbox-tts) (1.13.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.46.3->chatterbox-tts) (24.2)\n",
            "Collecting tokenizers<0.21,>=0.20 (from transformers==4.46.3->chatterbox-tts)\n",
            "  Downloading tokenizers-0.20.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.46.3->chatterbox-tts) (4.67.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch==2.6.0->chatterbox-tts) (1.3.0)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.115.12)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio) (0.6.0)\n",
            "Requirement already satisfied: gradio-client==1.10.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.10.1)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.18)\n",
            "Collecting pandas<3.0,>=1.0 (from gradio)\n",
            "  Downloading pandas-2.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (91 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.2/91.2 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.5)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.11.12)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.46.2)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.13.2)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.16.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.34.3)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.1->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.2->diffusers==0.29.0->chatterbox-tts) (1.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Collecting pre-commit (from s3tokenizer->chatterbox-tts)\n",
            "  Downloading pre_commit-4.2.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting onnx (from s3tokenizer->chatterbox-tts)\n",
            "  Downloading onnx-1.18.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa==0.10.0->chatterbox-tts) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.0->librosa==0.10.0->chatterbox-tts) (4.3.8)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers==0.29.0->chatterbox-tts) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers==0.29.0->chatterbox-tts) (2.4.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.20.0->librosa==0.10.0->chatterbox-tts) (3.6.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.1->librosa==0.10.0->chatterbox-tts) (1.17.1)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata->diffusers==0.29.0->chatterbox-tts) (3.22.0)\n",
            "Requirement already satisfied: protobuf>=4.25.1 in /usr/local/lib/python3.11/dist-packages (from onnx->s3tokenizer->chatterbox-tts) (5.29.5)\n",
            "Collecting cfgv>=2.0.0 (from pre-commit->s3tokenizer->chatterbox-tts)\n",
            "  Downloading cfgv-3.4.0-py2.py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting identify>=1.0.0 (from pre-commit->s3tokenizer->chatterbox-tts)\n",
            "  Downloading identify-2.6.12-py2.py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting nodeenv>=0.11.1 (from pre-commit->s3tokenizer->chatterbox-tts)\n",
            "  Downloading nodeenv-1.9.1-py2.py3-none-any.whl.metadata (21 kB)\n",
            "Collecting virtualenv>=20.10.0 (from pre-commit->s3tokenizer->chatterbox-tts)\n",
            "  Downloading virtualenv-20.31.2-py3-none-any.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa==0.10.0->chatterbox-tts) (2.22)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Collecting distlib<1,>=0.3.7 (from virtualenv>=20.10.0->pre-commit->s3tokenizer->chatterbox-tts)\n",
            "  Downloading distlib-0.3.9-py2.py3-none-any.whl.metadata (5.2 kB)\n",
            "Downloading chatterbox_tts-0.1.1-py3-none-any.whl (91 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.4/91.4 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading conformer-0.3.2-py3-none-any.whl (4.3 kB)\n",
            "Downloading diffusers-0.29.0-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m59.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading librosa-0.10.0-py3-none-any.whl (252 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m252.9/252.9 kB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m86.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading resampy-0.4.3-py3-none-any.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m112.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading resemble_perth-1.0.1-py3-none-any.whl (34.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.4/34.4 MB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.6.0-cp311-cp311-manylinux1_x86_64.whl (766.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m766.7/766.7 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchaudio-2.6.0-cp311-cp311-manylinux1_x86_64.whl (3.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m64.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading transformers-4.46.3-py3-none-any.whl (10.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m61.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m112.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m95.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m60.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m97.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pandas-2.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m126.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.20.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m100.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnx-1.18.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m106.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pre_commit-4.2.0-py2.py3-none-any.whl (220 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m220.7/220.7 kB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cfgv-3.4.0-py2.py3-none-any.whl (7.2 kB)\n",
            "Downloading identify-2.6.12-py2.py3-none-any.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nodeenv-1.9.1-py2.py3-none-any.whl (22 kB)\n",
            "Downloading virtualenv-20.31.2-py3-none-any.whl (6.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m121.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading distlib-0.3.9-py2.py3-none-any.whl (468 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.0/469.0 kB\u001b[0m \u001b[31m39.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: s3tokenizer\n",
            "  Building wheel for s3tokenizer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for s3tokenizer: filename=s3tokenizer-0.1.7-py3-none-any.whl size=217370 sha256=3e9551bf13f79835231edcb52d40e43061a4e7dbaa5a91f666e41b811396c959\n",
            "  Stored in directory: /root/.cache/pip/wheels/11/b2/ca/8a985600c6eabc662f3bc651ea76281b2d35a6f2a99d715da5\n",
            "Successfully built s3tokenizer\n",
            "Installing collected packages: distlib, virtualenv, resemble-perth, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, nodeenv, identify, cfgv, pre-commit, pandas, onnx, nvidia-cusparse-cu12, nvidia-cudnn-cu12, tokenizers, resampy, nvidia-cusolver-cu12, diffusers, transformers, torch, librosa, torchaudio, conformer, s3tokenizer, chatterbox-tts\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.21.1\n",
            "    Uninstalling tokenizers-0.21.1:\n",
            "      Successfully uninstalled tokenizers-0.21.1\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: diffusers\n",
            "    Found existing installation: diffusers 0.33.1\n",
            "    Uninstalling diffusers-0.33.1:\n",
            "      Successfully uninstalled diffusers-0.33.1\n",
            "  Attempting uninstall: librosa\n",
            "    Found existing installation: librosa 0.11.0\n",
            "    Uninstalling librosa-0.11.0:\n",
            "      Successfully uninstalled librosa-0.11.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.3.0 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.0 which is incompatible.\n",
            "cudf-cu12 25.2.1 requires pandas<2.2.4dev0,>=2.0, but you have pandas 2.3.0 which is incompatible.\n",
            "dask-cudf-cu12 25.2.2 requires pandas<2.2.4dev0,>=2.0, but you have pandas 2.3.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed cfgv-3.4.0 chatterbox-tts-0.1.1 conformer-0.3.2 diffusers-0.29.0 distlib-0.3.9 identify-2.6.12 librosa-0.10.0 nodeenv-1.9.1 numpy-1.26.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 onnx-1.18.0 pandas-2.3.0 pre-commit-4.2.0 resampy-0.4.3 resemble-perth-1.0.1 s3tokenizer-0.1.7 tokenizers-0.20.3 torch-2.6.0 torchaudio-2.6.0 transformers-4.46.3 virtualenv-20.31.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torch",
                  "torchaudio",
                  "torchgen",
                  "torio"
                ]
              },
              "id": "a144999f4a0340c3b70ce9e766487a2a"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make sure you have run this cell in a fresh runtime:\n",
        "# !pip install chatterbox-tts gradio\n",
        "\n",
        "import gradio as gr\n",
        "import torchaudio as ta\n",
        "from chatterbox.tts import ChatterboxTTS\n",
        "import os\n",
        "import logging\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "# Set up logging\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "\n",
        "# --- Define device ---\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "logging.info(f\"Running on device: {DEVICE}\")\n",
        "\n",
        "# --- Global Model Initialization ---\n",
        "logging.info(\"Loading Chatterbox-TTS model...\")\n",
        "model = ChatterboxTTS.from_pretrained(device=DEVICE)\n",
        "logging.info(\"Model loaded successfully.\")\n",
        "\n",
        "\n",
        "def set_seed(seed: int):\n",
        "    \"\"\"Sets the random seed for reproducibility across torch, numpy, and random.\"\"\"\n",
        "    if seed == 0: # A seed of 0 will be treated as random\n",
        "        seed = random.randint(1, 1_000_000)\n",
        "    logging.info(f\"Using random seed: {seed}\")\n",
        "    torch.manual_seed(seed)\n",
        "    if DEVICE == \"cuda\":\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "\n",
        "# --- Main TTS Function ---\n",
        "def text_to_speech(text, audio_prompt, exaggeration, cfg_weight, temperature, seed, max_chars):\n",
        "    \"\"\"\n",
        "    Generates speech from text, dynamically truncating based on the max_chars slider.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # --- Input validation ---\n",
        "        if not text or not text.strip():\n",
        "            raise gr.Error(\"Please provide some text to synthesize.\")\n",
        "\n",
        "        # Truncate text using the value from the max_chars slider\n",
        "        max_chars = int(max_chars)\n",
        "        if len(text) > max_chars:\n",
        "            logging.warning(f\"Text length ({len(text)}) exceeds limit ({max_chars}). Truncating.\")\n",
        "            text = text[:max_chars]\n",
        "\n",
        "        # Set the seed for reproducibility\n",
        "        set_seed(int(seed))\n",
        "\n",
        "        # --- THIS IS THE CORRECTED LOGIC ---\n",
        "\n",
        "        # The 'audio_prompt' variable from Gradio is either a filepath (str) or None.\n",
        "        prompt_path = audio_prompt\n",
        "        logging.info(f\"Received audio prompt path from Gradio: {prompt_path} (Type: {type(prompt_path)})\")\n",
        "\n",
        "        # The model's generate function is designed to handle audio_prompt_path being None.\n",
        "        # We can pass it directly.\n",
        "        generate_args = {\n",
        "            'text': text,\n",
        "            'audio_prompt_path': prompt_path,\n",
        "            'exaggeration': exaggeration,\n",
        "            'temperature': temperature,\n",
        "            'cfg_weight': cfg_weight\n",
        "        }\n",
        "\n",
        "        # Log which voice is being used and check for file existence only if a path is given.\n",
        "        if prompt_path:\n",
        "            if not os.path.exists(prompt_path):\n",
        "                 raise gr.Error(f\"Audio prompt file not found at temporary path: {prompt_path}. Please try re-uploading.\")\n",
        "            logging.info(f\"Generating speech with audio prompt: {prompt_path}\")\n",
        "        else:\n",
        "            logging.info(\"No audio prompt provided. Generating speech with default voice.\")\n",
        "\n",
        "        # Single, clean call to the model\n",
        "        wav = model.generate(**generate_args)\n",
        "\n",
        "        # ------------------------------------\n",
        "\n",
        "        output_path = \"generated_speech.wav\"\n",
        "        ta.save(output_path, wav.cpu(), model.sr)\n",
        "        logging.info(f\"Speech saved to {output_path}\")\n",
        "\n",
        "        return output_path\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.error(f\"An error occurred: {e}\", exc_info=True)\n",
        "        if isinstance(e, gr.Error):\n",
        "             raise e\n",
        "        raise gr.Error(f\"An error occurred during speech generation: {e}\")\n",
        "\n",
        "\n",
        "# --- Gradio UI with default theme ---\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\n",
        "        \"\"\"\n",
        "        # Chatterbox-TTS Gradio Demo\n",
        "        Generate speech from text with reference audio styling.\n",
        "        **Note**: Text longer than the selected max characters will be automatically shortened.\n",
        "        \"\"\"\n",
        "    )\n",
        "    with gr.Row():\n",
        "        with gr.Column(scale=2):\n",
        "            text_input = gr.Textbox(\n",
        "                lines=4,\n",
        "                label=\"Text to Synthesize\",\n",
        "                placeholder=\"Enter your text here...\"\n",
        "            )\n",
        "            audio_input = gr.Audio(\n",
        "                sources=[\"upload\", \"microphone\"],\n",
        "                type=\"filepath\",\n",
        "                label=\"Reference Audio File (Optional)\"\n",
        "            )\n",
        "\n",
        "            exaggeration_slider = gr.Slider(\n",
        "                minimum=0.25, maximum=2.0, step=0.05,\n",
        "                label=\"Exaggeration\",\n",
        "                info=\"Neutral = 0.5. Extreme values can be unstable.\",\n",
        "                value=0.5\n",
        "            )\n",
        "            cfg_slider = gr.Slider(\n",
        "                minimum=0.2, maximum=1.0, step=0.05,\n",
        "                label=\"CFG/Pace\",\n",
        "                info=\"Controls how strictly the model follows the text/prompt.\",\n",
        "                value=0.5\n",
        "            )\n",
        "\n",
        "            with gr.Accordion(\"More options\", open=False):\n",
        "                temp_slider = gr.Slider(\n",
        "                    minimum=0.05, maximum=5.0, step=0.05,\n",
        "                    label=\"Temperature\",\n",
        "                    info=\"Controls randomness. Higher values are more diverse.\",\n",
        "                    value=0.8\n",
        "                )\n",
        "                seed_input = gr.Number(\n",
        "                    value=0,\n",
        "                    label=\"Random Seed\",\n",
        "                    info=\"Set to 0 for a random seed.\"\n",
        "                )\n",
        "                max_chars_slider = gr.Slider(\n",
        "                    minimum=300, maximum=3000, step=200,\n",
        "                    label=\"Max Characters\",\n",
        "                    info=\"Sets the character limit for the input text. Longer text requires more processing time and memory.\",\n",
        "                    value=300\n",
        "                )\n",
        "\n",
        "            submit_button = gr.Button(\"Generate Speech\", variant=\"primary\")\n",
        "\n",
        "        with gr.Column(scale=1):\n",
        "            audio_output = gr.Audio(label=\"Generated Speech\", interactive=False)\n",
        "\n",
        "    submit_button.click(\n",
        "        fn=text_to_speech,\n",
        "        inputs=[\n",
        "            text_input,\n",
        "            audio_input,\n",
        "            exaggeration_slider,\n",
        "            cfg_slider,\n",
        "            temp_slider,\n",
        "            seed_input,\n",
        "            max_chars_slider\n",
        "        ],\n",
        "        outputs=audio_output,\n",
        "        api_name=\"tts\"\n",
        "    )\n",
        "\n",
        "# Launch the Gradio app\n",
        "demo.launch(share=True, debug=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 639
        },
        "id": "jW9LgvycCzBs",
        "outputId": "f118905a-adf8-4566-8113-343f29c7cc2e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'chatterbox'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-9e3f8fde71ee>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgradio\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mgr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorchaudio\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mchatterbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtts\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChatterboxTTS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'chatterbox'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make sure you have run this cell in a fresh runtime:\n",
        "# !pip install chatterbox-tts gradio\n",
        "\n",
        "import gradio as gr\n",
        "import torchaudio as ta\n",
        "from chatterbox.tts import ChatterboxTTS\n",
        "import os\n",
        "import logging\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "# Set up logging\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "\n",
        "# --- Define device ---\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "logging.info(f\"Running on device: {DEVICE}\")\n",
        "\n",
        "# --- Global Model Initialization ---\n",
        "logging.info(\"Loading Chatterbox-TTS model...\")\n",
        "model = ChatterboxTTS.from_pretrained(device=DEVICE)\n",
        "logging.info(\"Model loaded successfully.\")\n",
        "\n",
        "\n",
        "def set_seed(seed: int):\n",
        "    \"\"\"Sets the random seed for reproducibility across torch, numpy, and random.\"\"\"\n",
        "    if seed == 0: # A seed of 0 will be treated as random\n",
        "        seed = random.randint(1, 1_000_000)\n",
        "    logging.info(f\"Using random seed: {seed}\")\n",
        "    torch.manual_seed(seed)\n",
        "    if DEVICE == \"cuda\":\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "\n",
        "# --- Main TTS Function ---\n",
        "def text_to_speech(text, audio_prompt, exaggeration, cfg_weight, temperature, seed, max_chars):\n",
        "    \"\"\"\n",
        "    Generates speech from text. The total text is first capped by the max_chars slider.\n",
        "    If the remaining text is > 500 chars, it is split into chunks and generated sequentially.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        if not text or not text.strip():\n",
        "            raise gr.Error(\"Please provide some text to synthesize.\")\n",
        "\n",
        "        # First, honor the Max Characters slider as an overall cap on the text length.\n",
        "        max_chars = int(max_chars)+500\n",
        "        if len(text) > max_chars:\n",
        "            logging.warning(f\"Total text length ({len(text)}) exceeds slider limit ({max_chars}). Truncating total text.\")\n",
        "            text = text[:max_chars]\n",
        "\n",
        "        # Set the seed for reproducibility\n",
        "        set_seed(int(seed))\n",
        "\n",
        "        # Prepare common arguments for the model.\n",
        "        prompt_path = audio_prompt\n",
        "        generate_args = {\n",
        "            'audio_prompt_path': prompt_path,\n",
        "            'exaggeration': exaggeration,\n",
        "            'temperature': temperature,\n",
        "            'cfg_weight': cfg_weight\n",
        "        }\n",
        "\n",
        "        # --- MINIMAL CHANGE FOR CHUNKING LOGIC ---\n",
        "\n",
        "        CHUNK_SIZE = 500\n",
        "        # Split text into chunks of 500 characters\n",
        "        text_chunks = [text[i:i+CHUNK_SIZE] for i in range(0, len(text), CHUNK_SIZE)]\n",
        "\n",
        "        if len(text_chunks) > 1:\n",
        "            logging.info(f\"Text is long. Splitting into {len(text_chunks)} chunks of up to {CHUNK_SIZE} characters each.\")\n",
        "\n",
        "            wav_parts = []\n",
        "            for i, chunk in enumerate(text_chunks):\n",
        "                logging.info(f\"Generating audio for chunk {i+1}/{len(text_chunks)}...\")\n",
        "                generate_args['text'] = chunk\n",
        "                # Generate audio for the current chunk\n",
        "                wav_part = model.generate(**generate_args)\n",
        "                wav_parts.append(wav_part)\n",
        "\n",
        "            # Stitch the audio parts together\n",
        "            wav = torch.cat(wav_parts, dim=1)\n",
        "            logging.info(\"All chunks generated and concatenated successfully.\")\n",
        "\n",
        "        else:\n",
        "            # If there's only one chunk (or less), run the generation normally.\n",
        "            logging.info(f\"Generating speech for text: '{text[:50]}...'\")\n",
        "            generate_args['text'] = text\n",
        "            wav = model.generate(**generate_args)\n",
        "\n",
        "        # --- END OF CHANGE ---\n",
        "\n",
        "        output_path = \"generated_speech.wav\"\n",
        "        ta.save(output_path, wav.cpu(), model.sr)\n",
        "        logging.info(f\"Speech saved to {output_path}\")\n",
        "\n",
        "        return output_path\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.error(f\"An error occurred: {e}\", exc_info=True)\n",
        "        if isinstance(e, gr.Error):\n",
        "             raise e\n",
        "        raise gr.Error(f\"An error occurred during speech generation: {e}\")\n",
        "\n",
        "\n",
        "# --- Gradio UI with default theme ---\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\n",
        "        \"\"\"\n",
        "        # Chatterbox-TTS Gradio Demo\n",
        "        Generate speech from text with reference audio styling.\n",
        "        **Note**: Text longer than the selected max characters will be automatically shortened.\n",
        "        Text is processed in chunks of 500 characters to handle long inputs.\n",
        "        \"\"\"\n",
        "    )\n",
        "    with gr.Row():\n",
        "        with gr.Column(scale=2):\n",
        "            text_input = gr.Textbox(\n",
        "                lines=4,\n",
        "                label=\"Text to Synthesize\",\n",
        "                placeholder=\"Enter your text here...\"\n",
        "            )\n",
        "            audio_input = gr.Audio(\n",
        "                sources=[\"upload\", \"microphone\"],\n",
        "                type=\"filepath\",\n",
        "                label=\"Reference Audio File (Optional)\"\n",
        "            )\n",
        "\n",
        "            exaggeration_slider = gr.Slider(\n",
        "                minimum=0.25, maximum=2.0, step=0.05,\n",
        "                label=\"Exaggeration\",\n",
        "                info=\"Neutral = 0.5. Extreme values can be unstable.\",\n",
        "                value=0.5\n",
        "            )\n",
        "            cfg_slider = gr.Slider(\n",
        "                minimum=0.2, maximum=1.0, step=0.05,\n",
        "                label=\"CFG/Pace\",\n",
        "                info=\"Controls how strictly the model follows the text/prompt.\",\n",
        "                value=0.5\n",
        "            )\n",
        "\n",
        "            with gr.Accordion(\"More options\", open=False):\n",
        "                temp_slider = gr.Slider(\n",
        "                    minimum=0.05, maximum=5.0, step=0.05,\n",
        "                    label=\"Temperature\",\n",
        "                    info=\"Controls randomness. Higher values are more diverse.\",\n",
        "                    value=0.8\n",
        "                )\n",
        "                seed_input = gr.Number(\n",
        "                    value=0,\n",
        "                    label=\"Random Seed\",\n",
        "                    info=\"Set to 0 for a random seed.\"\n",
        "                )\n",
        "                max_chars_slider = gr.Slider(\n",
        "                    minimum=300, maximum=3000, step=200,\n",
        "                    label=\"Max Characters\",\n",
        "                    info=\"Sets the TOTAL character limit for the input text. Longer text requires more processing time and memory.\",\n",
        "                    value=3000 # Increased default to show capability\n",
        "                )\n",
        "\n",
        "            submit_button = gr.Button(\"Generate Speech\", variant=\"primary\")\n",
        "\n",
        "        with gr.Column(scale=1):\n",
        "            audio_output = gr.Audio(label=\"Generated Speech\", interactive=False)\n",
        "\n",
        "    submit_button.click(\n",
        "        fn=text_to_speech,\n",
        "        inputs=[\n",
        "            text_input,\n",
        "            audio_input,\n",
        "            exaggeration_slider,\n",
        "            cfg_slider,\n",
        "            temp_slider,\n",
        "            seed_input,\n",
        "            max_chars_slider\n",
        "        ],\n",
        "        outputs=audio_output,\n",
        "        api_name=\"tts\"\n",
        "    )\n",
        "\n",
        "# Launch the Gradio app\n",
        "demo.launch(share=True, debug=True)"
      ],
      "metadata": {
        "id": "_0qa4dcWh6EO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}